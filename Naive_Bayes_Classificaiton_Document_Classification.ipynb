{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Naive Bayes Classificaiton: Document Classification",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/msakarvadia/Machine-Learning/blob/master/Naive_Bayes_Classificaiton_Document_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "9JUWkOJJ8S59",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Probability and Statistics for AI & Machine Learning**\n",
        "## Document Classification using Naive Bayes Classifier.\n",
        "\n",
        " NC State University\n"
      ]
    },
    {
      "metadata": {
        "id": "TS8iGOT1fdOn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This code classifies the sentiment of IMDB movie reviews using a Naive Bayes Classifier. Because of the nature of this classifier our accuracy for classificiations will only hit around 80-85% due to our \"naive\" assumption that there are no dependencies between words in a moive review."
      ]
    },
    {
      "metadata": {
        "id": "wq1U3LBU7hQ-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Dataset "
      ]
    },
    {
      "metadata": {
        "id": "Q2aenG6M6JZA",
        "colab_type": "code",
        "outputId": "c0fa62a1-88d6-41e8-a61c-aa12a02e4a85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import imdb\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(path=\"imdb.npz\",\n",
        "                                                      num_words=None,\n",
        "                                                      skip_top=0,\n",
        "                                                      maxlen=None,\n",
        "                                                      seed=113,\n",
        "                                                      start_char=1,\n",
        "                                                      oov_char=2,\n",
        "                                                      index_from=3)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0hosq5UG83jl",
        "colab_type": "code",
        "outputId": "afcb818e-b532-4e65-9218-0cfc8040e5cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "\"\"\"print(x_test[10:40])\"\"\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'print(x_test[10:40])'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "W2tOScCwne6W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b1T24tdis1Iu",
        "colab_type": "code",
        "outputId": "c8b87013-1c97-4957-f798-11639b37b334",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "#determine total number of words in all positive documents and total words in negative documents\n",
        "oneWordCount = 0\n",
        "zeroWordCount = 0\n",
        "for i in range(25000):\n",
        "  if y_train[i]==1:\n",
        "    oneWordCount += len(x_train[i])\n",
        "  else:\n",
        "    zeroWordCount += len(x_train[i])\n",
        "  \n",
        "      \n",
        "print(oneWordCount)\n",
        "print(zeroWordCount)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3019537\n",
            "2948304\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xKf-qbbii-rG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#2 column array of [word, frequency] of one classified documents\n",
        "oneWordFreq = {}\n",
        "zeroWordFreq = {}\n",
        "\n",
        "#determine the fequency of each word in 1 classified documents and 0 classified documents and append values to frequency array defined above\n",
        "for i in range(25000):\n",
        "  if y_train[i] == 1:\n",
        "    for w in range(len(x_train[i])):\n",
        "      oneWordFreq[x_train[i][w]] = oneWordFreq.get(x_train[i][w],0)+1\n",
        "  if y_train[i] ==0:\n",
        "    for w in range(len(x_train[i])):\n",
        "      zeroWordFreq[x_train[i][w]] = zeroWordFreq.get(x_train[i][w],0)+1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "darcG4UtGmEf",
        "colab_type": "code",
        "outputId": "ae59138b-3537-4fe4-adc7-3be6906d3fa2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "#checks to make sure that the frequency counter is accuratly counting frequencies by summing all of them up and seeing if they match the total word count\n",
        "total = 0\n",
        "a=0\n",
        "for k,v in oneWordFreq.items():\n",
        "  total += v\n",
        "  a+=1\n",
        "print(total)\n",
        "\n",
        "totalTwo = 0\n",
        "for k,v in zeroWordFreq.items():\n",
        "  totalTwo += v\n",
        "print(totalTwo)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3019537\n",
            "2948304\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "enr6-0v-GmND",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#In order to account for words in the test set that arnt in the training set we will use a laplace function\n",
        "#add 10,000 to the total word count; this is our assumption for the amount of vocab words possible\n",
        "oneWordCount += 10000\n",
        "zeroWordCount += 10000\n",
        "\n",
        "#to complete the laplace funciton, we add one to the frequency of of all words\n",
        "for k,v in oneWordFreq.items():\n",
        "  oneWordFreq[k]= v+1\n",
        "  \n",
        "for k,v in zeroWordFreq.items():\n",
        "  zeroWordFreq[k]= v+1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VDPvC_J2jCvT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#we must now assume that the probablity of words occuring are independant...this is an untrue and naive assumption but we need this to simplfy things and use conditional probability\n",
        "#P(word|Classification) = Freq of word + 1 / Total # of words + 10000\n",
        "\n",
        "for k,v in oneWordFreq.items():\n",
        "  oneWordFreq[k]= v/oneWordCount\n",
        "for a,b in zeroWordFreq.items():\n",
        "  zeroWordFreq[a] = b/zeroWordCount"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "28EFMMGwbfia",
        "colab_type": "code",
        "outputId": "e2e96aa8-7cbc-4a6d-d8c2-5cc7861b6863",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "\"\"\"print(sorted(oneWordFreq.items(), key=lambda s: s[0]))\"\"\""
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'print(sorted(oneWordFreq.items(), key=lambda s: s[0]))'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "zSkHtcHwbgUt",
        "colab_type": "code",
        "outputId": "5dfa7f1a-68cc-4135-f7f5-45907967a704",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "\"\"\"print(sorted(zeroWordFreq.items(), key=lambda s: s[0]))\"\"\""
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'print(sorted(zeroWordFreq.items(), key=lambda s: s[0]))'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "MrWn1JWCpBNK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# if there is a new word in the test set, eventhough we have the laplace function, the probability will still approach zero since we are multiplying; instead we take the log of each individual probbility and add them\n",
        "negChecker = 0\n",
        "for k,v in oneWordFreq.items():\n",
        "  oneWordFreq[k]= math.log(v)\n",
        "for k,v in zeroWordFreq.items():\n",
        "  zeroWordFreq[k]= math.log(v)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NO0ST0hGYqOS",
        "colab_type": "code",
        "outputId": "0ac91b38-d659-4420-c62a-12997609422d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "\"\"\"print(oneWordFreq.items())\"\"\""
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'print(oneWordFreq.items())'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "NZ0dbC-yaUDZ",
        "colab_type": "code",
        "outputId": "04a3dcdc-b89f-4744-abf1-d1b6154caba8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "\"\"\"print(zeroWordFreq.items())\"\"\""
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'print(zeroWordFreq.items())'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "E90j7cTLVp-_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#for every review we calculate the total sum of all of the oneWordFreq of indepentant word probabilites and sum them up and do the same for zeroWordFreq\n",
        "#compare which one is greater for each line...and voila that is your class\n",
        "\n",
        "#we will have to still check that keys are in range and if not do 1/__WordCount\n",
        "\n",
        "def oneTrainer(x_train, y_train):\n",
        "  oneProb = []\n",
        "  for i in range(25000):\n",
        "      oneRowProb = 0\n",
        "      zeroRowProb = 0\n",
        "      for w in x_train[i]:\n",
        "        word = w\n",
        "        if w in oneWordFreq.keys():\n",
        "          oneRowProb += oneWordFreq[word]\n",
        "        else:\n",
        "          oneRowProb += math.log(1/oneWordCount)\n",
        "      oneProb.append(oneRowProb)\n",
        "  return oneProb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LfTmtBYfatRr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def zeroTrainer(x_train, y_train):\n",
        "  zeroProb = []\n",
        "  for i in range(25000):\n",
        "      oneRowProb = 0\n",
        "      zeroRowProb = 0\n",
        "      for w in x_train[i]:\n",
        "        word = w    \n",
        "        if w in zeroWordFreq.keys():\n",
        "          zeroRowProb += zeroWordFreq[word]\n",
        "        else:\n",
        "          zeroRowProb += math.log(1/zeroWordCount)\n",
        "      zeroProb.append(zeroRowProb)\n",
        "  return zeroProb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UkM3i-ZpigHL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def errorCheck(oneProb, zeroProb, y_train):\n",
        "  checkerArr = []\n",
        "  error = 0\n",
        "  for i in range(25000):\n",
        "    if oneProb[i]>zeroProb[i]:\n",
        "      checkerArr.append(1)\n",
        "    else:\n",
        "      checkerArr.append(0)\n",
        "    if y_train[i] != checkerArr[i]:\n",
        "      error +=1\n",
        "  return (error/25000)*100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GGn43DlXeVj9",
        "colab_type": "code",
        "outputId": "8c7695b3-58e2-46c2-b777-be27378ea628",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "#this is where we check our naive bayes classifier with test set data\n",
        "one = oneTrainer(x_test, y_test)\n",
        "zero = zeroTrainer(x_test, y_test)\n",
        "errorCheck(one, zero, y_test)\n",
        "accuracy = 0\n",
        "accuracy = 100 - errorCheck(one, zero, y_test)\n",
        "print(\"Accuracy is\", accuracy, \"%\")\n",
        "end_time = time.time()\n",
        "print(\"Total execution time: {}\".format(end_time - start_time))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy is 81.27199999999999 %\n",
            "Total execution time: 16.617316246032715\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}